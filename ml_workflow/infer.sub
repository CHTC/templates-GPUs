universe = container
docker_image = docker://iaross/catdog:with_inference
# container_image = file:///staging/iaross/catdog_with_inference.sif # see our guide on converting

request_disk = $(disk:500MB)
request_memory = $(memory:6GB)
request_cpus = $(cpus:1)
request_gpus = 1
gpus_minimum_capability = 7.5
gpus_minimum_memory = 4096
+WantGPULab = true
+GPUJobLength = "short"

executable = /bin/bash
transfer_executable = false
arguments = infer.sh

transfer_input_files = infer.sh,model.pth,file:///staging/iaross/cat_dog/images.zip
transfer_output_files = output
should_transfer_files = YES
when_to_transfer_output = ON_EXIT_OR_EVICT

output = $(CLUSTERID).out
error = $(CLUSTERID).err
log = catdog_inference.log

queue
